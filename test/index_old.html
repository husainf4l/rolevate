<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        h1 { 
            color: white;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        .controls {
            background: white;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            margin-bottom: 30px;
            text-align: center;
        }
        .record-btn {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            border: none;
            padding: 20px 50px;
            font-size: 1.2em;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        .record-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 7px 20px rgba(0,0,0,0.3);
        }
        .record-btn.recording {
            background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        .status {
            margin-top: 20px;
            font-size: 1.1em;
            color: #555;
            min-height: 30px;
        }
        .status.recording {
            color: #f5576c;
            font-weight: bold;
        }
        .comparison-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }
        .model-card {
            background: white;
            padding: 25px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }
        .model-card h2 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.8em;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }
        .transcription {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            min-height: 200px;
            font-size: 1.2em;
            line-height: 1.8;
            color: #333;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        .transcription.empty {
            color: #999;
            font-style: italic;
        }
        .stats {
            margin-top: 15px;
            padding: 15px;
            background: #e9ecef;
            border-radius: 8px;
            font-size: 0.9em;
        }
        .stats-item {
            display: inline-block;
            margin-left: 20px;
            color: #666;
        }
        .stats-item strong {
            color: #333;
        }
        @media (max-width: 768px) {
            .comparison-container {
                grid-template-columns: 1fr;
            }
            h1 {
                font-size: 1.8em;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¤ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±</h1>
        
        <div class="controls">
            <button id="recordBtn" class="record-btn" onclick="toggleRecording()">
                ğŸ™ï¸ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„ØªØ¹Ø±Ù Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
            </button>
            <div id="status" class="status"></div>
        </div>

        <div class="comparison-container">
            <div class="model-card">
                <h2>ğŸ”µ Google Speech-to-Text</h2>
                <div class="transcription empty" id="google-transcription">
                    Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„Ù„Ø¨Ø¯Ø¡...
                </div>
                <div class="stats">
                    <span class="stats-item"><strong>Ø§Ù„ÙˆÙ‚Øª:</strong> <span id="google-time">--</span></span>
                    <span class="stats-item"><strong>Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª:</strong> <span id="google-words">0</span></span>
                </div>
            </div>

            <div class="model-card">
                <h2>ğŸŸ¢ OpenAI Whisper</h2>
                <div class="transcription empty" id="whisper-transcription">
                    Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„Ù„Ø¨Ø¯Ø¡...
                </div>
                <div class="stats">
                    <span class="stats-item"><strong>Ø§Ù„ÙˆÙ‚Øª:</strong> <span id="whisper-time">--</span></span>
                    <span class="stats-item"><strong>Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª:</strong> <span id="whisper-words">0</span></span>
                </div>
            </div>
        </div>
    </div>

    <script>
        let googleWs = null;
        let whisperWs = null;
        let mediaRecorder;
        let audioContext;
        let isRecording = false;

        function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new AudioContext({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);

                isRecording = true;

                // Update UI
                const btn = document.getElementById('recordBtn');
                btn.textContent = 'â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„';
                btn.classList.add('recording');
                document.getElementById('status').textContent = 'ğŸ”´ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„Ù†Ø³Ø® Ø§Ù„Ù…Ø¨Ø§Ø´Ø±...';
                document.getElementById('status').classList.add('recording');

                // Clear previous results
                resetTranscriptions();

                // Connect to WebSockets
                googleWs = new WebSocket('ws://localhost:8001/ws/google');
                whisperWs = new WebSocket('ws://localhost:8001/ws/whisper');

                let googleTranscript = '';
                let whisperTranscript = '';
                let googleStartTime = Date.now();
                let whisperStartTime = Date.now();

                googleWs.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    if (data.error) {
                        updateTranscription('google', data.error, '--');
                    } else {
                        if (data.is_final) {
                            googleTranscript += data.transcript + ' ';
                            googleStartTime = Date.now();
                        } else {
                            const tempTranscript = googleTranscript + data.transcript;
                            const duration = ((Date.now() - googleStartTime) / 1000).toFixed(2);
                            updateTranscription('google', tempTranscript, duration);
                        }
                    }
                };

                whisperWs.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    if (data.error) {
                        updateTranscription('whisper', data.error, '--');
                    } else {
                        whisperTranscript += data.transcript + ' ';
                        const duration = ((Date.now() - whisperStartTime) / 1000).toFixed(2);
                        updateTranscription('whisper', whisperTranscript, duration);
                    }
                };

                // Process audio data
                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;

                    const inputData = e.inputBuffer.getChannelData(0);
                    const pcmData = convertFloat32ToInt16(inputData);

                    if (googleWs && googleWs.readyState === WebSocket.OPEN) {
                        googleWs.send(pcmData);
                    }
                    if (whisperWs && whisperWs.readyState === WebSocket.OPEN) {
                        whisperWs.send(pcmData);
                    }
                };

                source.connect(processor);
                processor.connect(audioContext.destination);

                // Store for cleanup
                window.audioStream = stream;
                window.audioProcessor = processor;

            } catch (error) {
                alert('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†: ' + error.message);
                resetRecording();
            }
        }

        function stopRecording() {
            isRecording = false;

            if (window.audioProcessor) {
                window.audioProcessor.disconnect();
            }
            if (audioContext) {
                audioContext.close();
            }
            if (window.audioStream) {
                window.audioStream.getTracks().forEach(track => track.stop());
            }
            if (googleWs) {
                googleWs.close();
            }
            if (whisperWs) {
                whisperWs.send(JSON.stringify({ type: 'stop' }));
                whisperWs.close();
            }

            const btn = document.getElementById('recordBtn');
            btn.textContent = 'ğŸ™ï¸ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„ØªØ¹Ø±Ù Ø§Ù„Ù…Ø¨Ø§Ø´Ø±';
            btn.classList.remove('recording');
            document.getElementById('status').textContent = 'âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª';
            document.getElementById('status').classList.remove('recording');
        }

        function convertFloat32ToInt16(buffer) {
            const l = buffer.length;
            const buf = new Int16Array(l);
            for (let i = 0; i < l; i++) {
                buf[i] = Math.min(1, buffer[i]) * 0x7FFF;
            }
            return buf.buffer;
        }

        function updateTranscription(model, text, duration) {
            const transcriptionEl = document.getElementById(`${model}-transcription`);
            const timeEl = document.getElementById(`${model}-time`);
            const wordsEl = document.getElementById(`${model}-words`);

            transcriptionEl.textContent = text || 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹...';
            transcriptionEl.classList.remove('empty');
            timeEl.textContent = `${duration}s`;
            
            // Count words (split by spaces for Arabic)
            const wordCount = text ? text.trim().split(/\s+/).length : 0;
            wordsEl.textContent = wordCount;
        }

        function resetTranscriptions() {
            ['google', 'whisper'].forEach(model => {
                document.getElementById(`${model}-transcription`).textContent = 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹...';
                document.getElementById(`${model}-transcription`).classList.add('empty');
                document.getElementById(`${model}-time`).textContent = '0.00';
                document.getElementById(`${model}-words`).textContent = '0';
            });
        }

        function resetRecording() {
            isRecording = false;
            const btn = document.getElementById('recordBtn');
            btn.textContent = 'ğŸ™ï¸ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„ØªØ¹Ø±Ù Ø§Ù„Ù…Ø¨Ø§Ø´Ø±';
            btn.classList.remove('recording');
            document.getElementById('status').textContent = '';
            document.getElementById('status').classList.remove('recording');
        }
    </script>
</body>
</html>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .model { border: 1px solid #ccc; padding: 10px; margin: 10px 0; }
        .model h2 { margin-top: 0; }
        .transcription { background-color: #f9f9f9; padding: 10px; white-space: pre-wrap; }
    </style>
</head>
<body>
    <h1>Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ</h1>
    <p>Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø© ØªØ¹Ø±Ø¶ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØªÙ„ÙØ© Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ. Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙƒ Ù…Ø¨Ø§Ø´Ø±Ø©.</p>
    <div id="status" style="font-weight: bold; color: red;"></div>

    <div class="model">
        <h2>Google Speech-to-Text</h2>
        <button onclick="startRecording('google')">ØªØ³Ø¬ÙŠÙ„ ÙˆØªØ¹Ø±Ù</button>
        <div class="transcription" id="google-transcription">Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ø³ÙŠØ¸Ù‡Ø± Ù‡Ù†Ø§...</div>
    </div>

    <div class="model">
        <h2>Azure Speech Services</h2>
        <button onclick="startRecording('azure')">ØªØ³Ø¬ÙŠÙ„ ÙˆØªØ¹Ø±Ù</button>
        <div class="transcription" id="azure-transcription">Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ø³ÙŠØ¸Ù‡Ø± Ù‡Ù†Ø§...</div>
    </div>

    <div class="model">
        <h2>AWS Transcribe</h2>
        <button onclick="startRecording('aws')">ØªØ³Ø¬ÙŠÙ„ ÙˆØªØ¹Ø±Ù</button>
        <div class="transcription" id="aws-transcription">Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ø³ÙŠØ¸Ù‡Ø± Ù‡Ù†Ø§...</div>
    </div>

    <div class="model">
        <h2>OpenAI Whisper</h2>
        <button onclick="startRecording('whisper')">ØªØ³Ø¬ÙŠÙ„ ÙˆØªØ¹Ø±Ù</button>
        <div class="transcription" id="whisper-transcription">Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ø³ÙŠØ¸Ù‡Ø± Ù‡Ù†Ø§...</div>
    </div>

    <div class="model">
        <h2>ØªØ¹Ø±Ù Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­ (Browser)</h2>
        <button onclick="startLiveTranscription()">Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ù…Ø¨Ø§Ø´Ø±</button>
        <button onclick="stopLiveTranscription()">Ø¥ÙŠÙ‚Ø§Ù</button>
        <div class="transcription" id="live-transcription">Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ø³ÙŠØ¸Ù‡Ø± Ù‡Ù†Ø§...</div>
    </div>

    <div class="model">
        <h2>ØªØ¹Ø±Ù Ù…Ø¨Ø§Ø´Ø± Ø¹Ø¨Ø± WebSocket</h2>
        <button onclick="startLiveTranscriptionWS('google')">Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Google)</button>
        <button onclick="startLiveTranscriptionWS('whisper')">Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Whisper)</button>
        <div class="transcription" id="ws-transcription">Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ø³ÙŠØ¸Ù‡Ø± Ù‡Ù†Ø§...</div>
    </div>

    <script>
        let mediaRecorder;
        let recordedChunks = [];

        async function startRecording(model) {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                recordedChunks = [];
                document.getElementById('status').textContent = 'Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„...';
                mediaRecorder.ondataavailable = event => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                mediaRecorder.onstop = () => {
                    document.getElementById('status').textContent = 'ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù...';
                    const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                    sendAudio(blob, model);
                    stream.getTracks().forEach(track => track.stop());
                };
                mediaRecorder.start();
                // Stop recording after 10 seconds
                setTimeout(() => {
                    if (mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                    }
                }, 10000);
            } catch (error) {
                alert('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†: ' + error.message);
            }
        }

        async function sendAudio(blob, model) {
            const formData = new FormData();
            formData.append('audio', blob, 'audio.webm');
            document.getElementById('status').textContent = 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ ÙˆØ§Ù„ØªØ¹Ø±Ù...';
            try {
                const response = await fetch(`http://localhost:8001/transcribe/${model}`, {
                    method: 'POST',
                    body: formData
                });
                const data = await response.json();
                document.getElementById(`${model}-transcription`).textContent = data.result;
                document.getElementById('status').textContent = '';
            } catch (error) {
                document.getElementById(`${model}-transcription`).textContent = 'Ø®Ø·Ø£: ' + error.message;
                document.getElementById('status').textContent = '';
            }
        }

        let recognition;

        function startLiveTranscription() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                alert('Ø§Ù„Ù…ØªØµÙØ­ Ù„Ø§ ÙŠØ¯Ø¹Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…');
                return;
            }
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = 'ar-SA';
            recognition.interimResults = false;
            recognition.continuous = true;
            recognition.onresult = function(event) {
                let transcript = '';
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    transcript += event.results[i][0].transcript;
                }
                document.getElementById('live-transcription').textContent = transcript;
            };
            recognition.onend = function() {
                // Restart if continuous
                if (recognition.continuous) {
                    recognition.start();
                }
            };
            recognition.start();
        }

        function stopLiveTranscription() {
            if (recognition) {
                recognition.stop();
                recognition.continuous = false;
            }
        }

        function startLiveTranscriptionWS(model) {
            const ws = new WebSocket(`ws://localhost:8001/ws/${model}`);
            ws.onopen = () => {
                startRecordingWS(ws);
            };
            ws.onmessage = (event) => {
                document.getElementById('ws-transcription').textContent = event.data;
            };
            ws.onclose = () => {
                console.log('WebSocket closed');
            };
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
            };
        }

        function startRecordingWS(ws) {
            navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
                const mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
                mediaRecorder.ondataavailable = event => {
                    if (event.data.size > 0) {
                        event.data.arrayBuffer().then(buffer => {
                            const base64 = btoa(String.fromCharCode(...new Uint8Array(buffer)));
                            ws.send(JSON.stringify({type: 'audio', data: base64}));
                        });
                    }
                };
                mediaRecorder.start(1000); // Send chunks every 1 second
                document.getElementById('status').textContent = 'Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„Ø¥Ø±Ø³Ø§Ù„...';
                setTimeout(() => {
                    mediaRecorder.stop();
                    ws.send(JSON.stringify({type: 'stop'}));
                    stream.getTracks().forEach(track => track.stop());
                    document.getElementById('status').textContent = 'ØªÙ… Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù...';
                }, 10000);
            }).catch(error => {
                alert('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†: ' + error.message);
            });
        }
    </script>
</body>
</html>
